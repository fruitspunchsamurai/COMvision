<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Project IRIS by fruitspunchsamurai</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/fruitspunchsamurai/COMvision">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/fruitspunchsamurai/COMvision/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/fruitspunchsamurai/COMvision/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title"> 
          <a href="http://s1367.photobucket.com/user/BrianSYC/media/Clear-Vision-315x851_zps7e30e243.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/Clear-Vision-315x851_zps7e30e243.jpg" border="0" alt=" photo Clear-Vision-315x851_zps7e30e243.jpg"/></a>
          <h1>Project IRIS</h1>
          <p>Singapore Polytechnic [MDP] [AUV] Computer Vision </p> 
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/fruitspunchsamurai">fruitspunchsamurai</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="http://twitter.com/#!/michigangraham">mattgraham</a></span>
        </div>

        <h3>Welcome to Project IRIS</h3>

<p>Hello There! This is Brian from Singapore Polytechnic.~</p>  
 
<p>I am responsible for the computer vision modules for the Under Water Robot Project. This repository will contain all my codes to serve as backup as well as a guide for my juniors who will be taking over this project. I am trying my best to ensure that all my codes are heavily commented on to ensure easy understanding. Currently, my codes are written in Python. This is due to the fact that Python is an easy language to pick up as well as the fact that the Raspberry Pi runs predominantly on Python.</p> 
 
<p>Table of Contents:  <br> 
1.)=========Introduction============<br>
1.0--------The Under Water Robot Project <br>
1.1--------The Competition <br>
1.2--------Research <br>
1.3--------Testing an ROV <br>
2.)==============Setup==============<br>
2.0--------Setting up the Raspberry Pi <br>
2.1--------Your First Code <br>
2.2--------GitHub <br>
2.3--------Blinking LEDs <br>
2.4--------I2C, SPI <br> 
2.5--------Using a Wireless Network Adapter <br>
2.6--------Customising your Pi <br>
3.)=====Basic Image Processing======<br>
3.0--------Camera Testing Logs<br> 
3.1--------Still Image Processing<br>
3.2--------Image Processing with OpenCV<br> 
3.3--------Hough Transform <br>
4.)=============Testing=============<br>
4.0--------Testing the Program <br>
4.1--------Pool Testing <br>
5.)===========Known Issues==========<br>
5.0--------Bugs <br>
6.)=========Possibilities===========<br>
6.0--------Colour + Pattern
</p>  
  
<h3>[1.0] The Under Water Robot Project</h3>

<p>Project IRIS is a subset of the Under Water Robot Project. The main project is to [re]construct an Autonomous Underwater Vehicle(AUV). There are several groups of different disciplines working on this project and i am the leader of one of these groups(EEE). We are mainly in charge of the software aspects of the project.(Keyboard Warriors!) </p>  


<p>There are three people, including myself in the EEE group. Each of us have been assigned individual responsibilities as shown below: </p>  
 
<pre><code>Yong Boon ---> Compass & Depth Sensor
Wei Khang ----> Control Systems
Brian -----------> Computer Vision
</code></pre>  
 
<p>One of the AUVs.</p> 
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0372_zps2f8a6770.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0372_zps2f8a6770.jpg" border="0" alt=" photo IMG_0372_zps2f8a6770.jpg"/></a>
  
<p></p>  
 
<h3>[1.1] The Competition</h3> 
 
<p>The Singapore AUV Challenge 2013 was the most recent competition that our AUV participated in. The project was passed down to us just after the competition.(We got fourth!) Our AUV did not manage to make it through the gate and the motion of the robot was also very choppy.</p> 
 
<p>The video of the competition can be found here: </p> 
 
<iframe width="560" height="315" src="http://www.youtube.com/embed/H0mIRADzzik" frameborder="0" allowfullscreen></iframe> 
 
<p></p>  
  
<h3>[1.2] Getting Down To Business</h3> 
 
<p>Why does the AUV need computer vision? Well without computer vision, the AUV would not be able to track the black line on the floor of the pool, avoid obstacles and detect and knock the flare. We are basically giving our robot vision!</p>

<p>Based on my research for about a month, i have made several discoveries as well as conclusions. Firstly, all the knowledge needed on computer vision to complete this task successfully, is simply scratching the surface of the topic of computer vision. Secondly since our project uses Raspberry Pi/BeagleBone Black, it is vital to know C++,C,Python and Linux commands at your fingertips. Last but not least, do take time to source out suitable components for the project. Not all cameras are compatible with Raspberry Pi/BeagleBoneBlack.</p>
 
<pre><code>Here are some useful links to get you started:
Camera Compatibility ----> <a href="http://elinux.org/RPi_VerifiedPeripherals#USB_Webcams">http://elinux.org/RPi_VerifiedPeripherals#USB_Webcams</a> 
Python Programming ------> <a href="http://www.codecademy.com/tracks/python">http://www.codecademy.com/tracks/python</a>
Basic Image Processing --> <a href="http://www.cl.cam.ac.uk/projects/raspberrypi/tutorials/robot/image_processing/">http://www.cl.cam.ac.uk/projects/raspberrypi/tutorials/robot/image_processing/</a>
Blob Detection ---------------> <a href="http://www.cl.cam.ac.uk/projects/raspberrypi/tutorials/robot/blob_detection/">http://www.cl.cam.ac.uk/projects/raspberrypi/tutorials/robot/blob_detection/</a>
</code></pre>   
 
<p>Not as easy as you think.</p> 
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0438_zps426999b1.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0438_zps426999b1.jpg" border="0" alt=" photo IMG_0438_zps426999b1.jpg"/></a>
  
<p></p> 
 
<h3>[1.3] Pool Day!</h3>

<p>No, no one is swimming. Only the Remotely Operated Vehicle(ROV) is swimming. Our supervisors brought us down to pool to demonstrate the ROV. Everyone from all the groups was present and we sure had fun.</p> 
 
<p>[The Nuclear Briefcase. Press to launch.]</p>
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0418_zps08e06409.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0418_zps08e06409.jpg" border="0" alt="&quot;The Briefcase&quot; photo IMG_0418_zps08e06409.jpg"/></a>
 
<p>[In you go!~]</p>
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0435_zps71e64174.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0435_zps71e64174.jpg" border="0" alt=" photo IMG_0435_zps71e64174.jpg"/></a> 
 
<p>[The vision is cool right?!]</p> 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0434_zpsf6489d44.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0434_zpsf6489d44.jpg" border="0" alt=" photo IMG_0434_zpsf6489d44.jpg"/></a>
<p></p> 
 
<h3>[2.0] Becoming a Keyboard Warrior</h3> 
 
                   <a href="http://3.bp.blogspot.com/-v0llcplZHx0/UUNFxf98eYI/AAAAAAAAEDo/7h-aipOWI-s/s640/KeyboardWarriors.jpg" target="_blank"><img src="http://3.bp.blogspot.com/-v0llcplZHx0/UUNFxf98eYI/AAAAAAAAEDo/7h-aipOWI-s/s640/KeyboardWarriors.jpg" border="0" alt=" photo KeyboardWarriors.jpg"/></a> 
 
<p></p> 
<p>Before you start reading this, please ensure that you are at least familiar with Linux commands as well as Python Programming, else you wont fully understand what i will be typing here.</p> 
 
<p>Whether you are using a Raspberry Pi or BeagleBone, the first step that i recommend you do is to familiarize yourself with the board. If you are using the Raspberry Pi, you need to have an OS flashed into an SD card.(We used Raspbian Wheezy) And so here is a guide on the pure basics of operating your embedded system. </p> 
 
<p>{Starting up the Raspberry Pi}<br>
1.) Connect your Pi to a power outlet.(5V,1A Don't turn it on yet!)<br>
2.) Connect the rest of the necessary peripherals.(E.g. Mouse, Keyboard, Screen) <br>
3.) Power on the Pi and wait for it to prompt you for your login and password.(Default login is pi, Default password is raspberry) <br>
4.) If this is the very first time you are setting up the Pi, type in <code>sudo raspi-config</code> to configure your Pi.(Use the arrow keys to control the UI)<br>
5.) Type in <code>startx</code>. This code is to launch the GUI desktop.($60 mini computer. Cool right?)<br>
6.) You can access the terminal again by double clicking on the LXTerminal icon on the desktop. <br>
7.) Type in <code>sudo shutdown -h now</code> to shutdown your Pi.</p>
  
<p>Congratualations! You have learnt to start up, configure and shutdown the Raspberry Pi. (Which is equivalent to learning how to shutdown and startup the PC you are using to view this now.)</p> 
 
<h3>[2.1] Your First Code!</h3>  
 
<p>This is where the real fun begins! There are a few things you need to take note of first though. On your GUI, there should be 2 icons, IDLE and IDLE 3. What's the difference? IDLE operates on Python V2.7 while IDLE 3 operates on Python V3.2. The difference between these two versions of Python can be found <a href="http://docs.python.org/3/whatsnew/3.0.html">here.</a> </p>  
  
<p>I'd recommend using Python V2.7 because alot of essential libraries are available there. Not all of them have been ported over to Python V3.2 yet. And so here begins the tutorial.~</p>  
 
<p>{Typing and Running your First Code}<br>
1.) Run IDLE or IDLE 3. The Python Shell window will appear.<br>
2.) Click File -> New Window.<br>
3.) Write your code on the new window. <br>
4.) To save your file. File -> Save As -> "filename".py (remember to add .py at the end so the system will recognise as a python file)<br>
5.) On the code window click Run -> Run Module. Your code will run on the Python Shell window.</p> 
<p>Have fun playing around!</p> 

<h3>[2.2] GitHub</h3> 
 
<p>What is Github? Github is a very very useful tool for you to install on your embedded system. This is because it serves as a backup for your codes. An exmaple would be what you are looking at now. This website is hosted by github pages and if you scroll up and click the "View on GitHub" link, you will see all the codes for GPIO testing, Computer Vision, etc that i have left for you.</p>  
 
<p>A detailed tutorial on how to install and use GitHub can be found <a href="https://help.github.com/articles/set-up-git">here.</a></p> 
 
<h3>[2.3] Blinking Some LEDs</h3>  
 
<p>This will be the first time you will be using your embedded system to control elements in the outside world. It may be confusing trying to do it the first time round so i'll try to make this as precise and simple as possible.</p>  
 
<p>Firstly, you are going to need to have a few things besides your embedded system.</p>  
 
<p>Seem familiar?</p> 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0440_zpsfae79c05.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0440_zpsfae79c05.jpg" border="0" alt=" photo IMG_0440_zpsfae79c05.jpg"/></a> 
 
<p>Connect it up!</p> 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/b4c8cc96-0250-45f3-9d72-646ddfbbcdc1_zps9e2a5269.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/b4c8cc96-0250-45f3-9d72-646ddfbbcdc1_zps9e2a5269.jpg" border="0" alt=" photo b4c8cc96-0250-45f3-9d72-646ddfbbcdc1_zps9e2a5269.jpg"/></a> 
 
<p></p> 
 
<p>Done with the hardware side? Now it's time for the software side. For the Raspberry Pi, you need to import in some new libraries in order to utilize the GPIO pins. Dont worry, it's not rocket science. Ensure that your internet on the Pi is working before you type in the codes below.</p>
 
<pre><code>Type in these codes on the LXTerminal of your Pi: 
sudo apt-get update && sudo apt-get upgrade 
sudo apt-get install python-dev 
sudo apt-get install python-rpi.gpio
</code></pre>  
 
<p>Congratualations! You are done configuring your Pi to use it's GPIO pins. You can get the source code to blink an LED in the repository. ("GPIOtest") Make sure you understand the code!</p> 
 
<p>Pin Diagram Allocations</p> 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0442_zpseb2e340c.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0442_zpseb2e340c.jpg" border="0" alt=" photo IMG_0442_zpseb2e340c.jpg"/></a> 
<p></p> 
  
<p>In your program, let's say you assign pin 11 to be an output pin. That pin you programmed will be GPIO no. 17. This is because pin 1 is the GPIO 3.3v, pin 2 is the GPIO 5v, pin 3 is the GPIO 2SDA, pin 4 is the GPIO 5V, etc...</p> 
 
<p>Ensure that when you connect up the wires of your LED test kit to your Pi, do NOT short circuit any of the pins together. (It could damage the board)</p> 
 
<p>Hmm? The program in the repository has an error message when you run it in the python shell? That's because you need to run the program as a root user!</p>
 
<pre><code>Open your LXTerminal and type these in: 
cd /home/pi/"Just list the directory path to where you saved the .py program to" 
sudo python GPIOtest.py
</code></pre> 

<p>If you still need more documentation, you can find it <a href="http://www.cl.cam.ac.uk/projects/raspberrypi/tutorials/robot/cheat_sheet/">here.</a></p> 
 
<h3>[2.4] Enabling I2C and SPI</h3>  
 
<p>So you have configured your Pi, blinked some LEDs and have a clear vision as to what needs to be done? Nice work!</p> 
 
<p>Before we can start to use external devices such as webcams or even another Arduino board, it is important to enable I2C and SPI protocols. What are they? I2C stands for Inter Integrated Circuit Communications while SPI stands for Serial-Peripheral-Interface. They are both communication protocols that allow a microcomputer to link to other micros or integrated circuits. Unfortunately, these protocols are blacklisted on the Raspberry Pi by default so we will need to fix that.</p>  
 
<p>Getting rid of the Blacklist: </p> 
<pre><code>Type in these codes on the LXTerminal of your Pi: 
sudo nano /etc/modprobe.d/raspi-blacklist.conf 
(Add a # in front of both the blacklisted lines) 
(Save and exit file) 
</code></pre>  
    
<p>Enable I2C</p> 
<pre><code>Type in these codes on the LXTerminal of your Pi: 
sudo nano /etc/modules 
(Add in i2c-dev below the last line) 
(Save and exit file) 
(Reboot Pi)
</code></pre>  
     
<p>Installing I2C tools: </p>  
<pre><code>Type in these codes on the LXTerminal of your Pi: 
sudo apt-get update
sudo apt-get install i2c-tools
</code></pre>   
  
<h3>[2.5] Using a Wireless Network Adapter</h3> 
 
<p>*This section is optional*</p> 
 
<p>There are a few ways to get a working Internet connection on the Raspberry Pi. Today, i will only be sharing 2 of the most commonly used ways.</p> 
 
<p>The first way is the simplest of them all. Just use an Ethernet cable and plug one end into a modem and the other into your Pi's ethernet port. Mission complete!! *If the connection doesnt seem to work, unplug the ethernet cable and wait for 20 seconds before trying again*</p>
   
<p>The second way is slightly more complicated and it is the main topic for this section. Using a Wireless Network Adapter. Some Wireless Network Adapters will require you to use a powered USB hub if the power consumption of the adapter is too high. This was the setup i used:</p> 
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0462_zps70424c31.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0462_zps70424c31.jpg" border="0" alt=" photo IMG_0462_zps70424c31.jpg"/></a> 
<p></p> 
 
<p>As you can see, the Wireless Network Adapter is connected to a powered USB hub. In the pictue below, you can see the results of plugging the Wireless Network Adapter. A description of each window is given below as well.</p> 
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/7a547b13-84a9-4005-a4b5-139d847c44cb_zps6d2a9392.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/7a547b13-84a9-4005-a4b5-139d847c44cb_zps6d2a9392.jpg" border="0" alt=" photo 7a547b13-84a9-4005-a4b5-139d847c44cb_zps6d2a9392.jpg"/></a> 
<p></p> 
 
<p>Topmost Window: This window shows that the Raspberry Pi detects the Wireless Network Adapter as "Realtek Semiconductor Corp. RTL8188CUS 802.11n WLAN Adapter.</p>  
<p>Bottom Left Window: This window shows that the Raspberry Pi WiFi configuration software detects the Wireless Network Adapter as WLAN0.</p> 
<p>Bottom Right Window: This window shows that the Wireless Network Adapter is able to scan for networks.</p> 

   
<h3>[2.6] Beauty is in the Pi of the Beholder...</h3>   
 
<p>Hey there! Be sure to customize your Pi however you see fit! There are a ton of ways to customise your Pi and i think it will be a good idea to invest some time into it since you will be with it for some period of time.</p> 
 
<p>Yeaaaaaaaaaa...!</p>  
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/2013-02-10-081325_1920x1200_scrot_zpsdc170c4a.png.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/2013-02-10-081325_1920x1200_scrot_zpsdc170c4a.png" border="0" alt=" photo 2013-02-10-081325_1920x1200_scrot_zpsdc170c4a.png"/></a> 
 
<p>Looks nice? No?</p> 
 
<p>So you're probably wondering how to take screenshots. You can do this by installing a program called "Scrot". With scrot you can take screenshots. This will be handy for picture documentation like i was doing.</p> 
 
<pre><code>Type in these codes on the LXTerminal of your Pi: 
sudo apt-get install scrot 
(Type in scrot in terminal to get a screenshot)
</code></pre> 
 
<p>Have fun!!</p>

 
<h3>[3.0] Camera Testing Logs</h3>  
 
<p>{First test [Creative Ltd webcam Notebook Ultra][VF0070]}</p> 
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0460_zpsd9a52bcd.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0460_zpsd9a52bcd.jpg" border="0" alt=" photo IMG_0460_zpsd9a52bcd.jpg"/></a> 
<p></p>  
 
<p>-Camera was able to be detected by Raspberry Pi.(click to view zoomed version)</p>  
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/c6c5fa1f-fea3-4712-bc84-5221980fb76f_zps18f85853.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/c6c5fa1f-fea3-4712-bc84-5221980fb76f_zps18f85853.jpg" border="0" alt=" photo c6c5fa1f-fea3-4712-bc84-5221980fb76f_zps18f85853.jpg"/></a> 
<p></p> 
 
<p>-The program was also able to set up the camera in specific resolutions.(click to view zoomed version)</p> 
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/c3fe9dbf-c95d-4e16-8dee-3e26c6ee8e6e_zpsafa6eb2c.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/c3fe9dbf-c95d-4e16-8dee-3e26c6ee8e6e_zpsafa6eb2c.jpg" border="0" alt=" photo c3fe9dbf-c95d-4e16-8dee-3e26c6ee8e6e_zpsafa6eb2c.jpg"/></a>  
<p></p> 
  
<p>-However Camera was unable to perform image capturing. When the program reads till the image capturing function, a black viewer window appears and then disappears within 2 seconds. The terminal returns to its normal state.</p> 
  
<p>------------------------------------------Overall Testing Failed------------------------------------------</p>
 
<p>{Second test [Raspberry Pi Official Camera Module]}</p> 
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/camera-raspberry-pi-wired-design-660x550_zpsae23229c.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/camera-raspberry-pi-wired-design-660x550_zpsae23229c.jpg" border="0" alt=" photo camera-raspberry-pi-wired-design-660x550_zpsae23229c.jpg"/></a>
  
<p></p>  
<p>This gadget is small yet powerful. It has a wide spectrum of commands for visual effects and has options for either still image or video capturing.</p> 
 
<p>Video on setting up with the Raspberry Pi:</p> 
<iframe width="560" height="315" src="http://www.youtube.com/embed/iLHij-mQVF4" frameborder="0" allowfullscreen></iframe> 
  
<p></p>  
<p>Unfortunately, we were unable to get our hands on this camera. It was released somewhere in the middle of May and was sold out within the first week. Thus, testing will have to be postponed until further notice.</p> 
  
<p></p>
<p>----------------------------Testing yet to be done until camera board arrives----------------------------</p>
 
<p>{Third test [Logitech Webcam C210]}</p>
  
<a href="http://www.infotechnow.com/images/c210_4.jpg?osCsid=0f1243006f88f7990bf7a75dae5991b2" target="_blank"><img src="http://www.infotechnow.com/images/c210_4.jpg?osCsid=0f1243006f88f7990bf7a75dae5991b2" border="0" alt="c210"/></a>
 
<p></p> 
<p>The Raspberry Pi was able to detect the Logitech C210 successfully.</p>  
 
<p>The CAMtest program run successful! </p>  
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/vid_result_zps49b25eb3.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/vid_result_zps49b25eb3.jpg" border="0" alt=" photo vid_result_zps49b25eb3.jpg"/></a> 
<p>What? I know my thumb is weird...</p>       
<p></p> 
 
<p>---------------------------------------!Overall Testing Successful!---------------------------------------</p> 
 
 
<h3>[3.1] Simple Image Processing (Still images)</h3>   
 
<p>*This section makes use of the imgproc library*</p>
 
<p>This will be the first time you will be trying to do something related to image processing! Excited? Before we can start, several conditions need to be met first. First, we are going to need the appropriate libraries to be imported to the processor board. We also have to ensure that the camera is able to interface with the processor board through I2C. For additional information on enabling I2C on your Pi, you go can <a href="http://quick2wire.com/articles/physical-python-part-1/">here.</a></p> 
 
<p>How does image processing work?</p>
 
<p></p>
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/Flowww_zps2421821b.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/Flowww_zps2421821b.jpg" border="0" alt=" photo Flowww_zps2421821b.jpg"/></a>
 
<p></p> 
 
<p>From the flowchart:  <br>
1) Webcam captures still image <br> 
2) Image is displayed on screen <br> 
3) Loop in program checks for pixels with Red Green Blue(RGB) ratio of more than 40 : 90 : 90 <br>
4) If a pixel's RGB ratio is not more than 40 : 90 : 90, pixel is changed into Cyan 0 : 255 : 255 <br>
5) New processed image is displayed on screen
</p>   
 
<p>*Do take note! The lower the resolution, the faster the processing!*</p> 
 
<p>Before you can get a successful run of the code, you need to have the imgproc library installed into your main processor board. You can find detailed information of how to do it <a href="http://www.cl.cam.ac.uk/projects/raspberrypi/tutorials/robot/downloads/#packages">here.</a> </p>
 
<p>There is a code in the repository for this (CAMtest). Do take a look at it and run it! It is natural that the FPS is horrendous though.</p>  
 
<h3>[3.2] Image Processing with OpenCV</h3> 
<p>As you may have noticed, the code (CAMtest) lags to infinity and beyond. Why is this so? One of the major reasons is that the code in CAMtest checks through each pixel while taking in three comparisons(Red, Green, Blue) at once. However, the new code in OpenCV only has one comparision! </p>  
 
<p>So what is OpenCV? OpenCV stands for Open Source Computer Vision. It is an incredible library of image processing functions. We will be using this library for our computer vision module.</p> 
 
<pre><code>Installing OpenCV: 
sudo apt-get install libopencv-dev python-opencv
</code></pre>

<p>Take a look at the blobdetection program in the repository. Here are some pitures of how it should look like in a successful run. </p> 
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/http-__makeagifcom_media_6-23-2013_MHd3Da_zpsf64581c6.gif.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/http-__makeagifcom_media_6-23-2013_MHd3Da_zpsf64581c6.gif" border="0" alt=" photo http-__makeagifcom_media_6-23-2013_MHd3Da_zpsf64581c6.gif"/></a> 
 
<a href="http://s1367.photobucket.com/user/BrianSYC/media/http-__makeagifcom_media_6-23-2013_6XipNF_zps9b6a560e.gif.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/http-__makeagifcom_media_6-23-2013_6XipNF_zps9b6a560e.gif" border="0" alt=" photo http-__makeagifcom_media_6-23-2013_6XipNF_zps9b6a560e.gif"/></a> 
<p></p> 
<p>As you can see, there are two .gif images. The one on the left shows a normal frame with a blue dot tracking my black notebook. The one on the right shows a black and white image, where the white parts of the image are the blobs detected as black. </p>
<p>The OpenCV program you see functioning above does not use the RGB/BGR colour space, instead it makes use of the Hue Saturation Value (HSV) colour space. You can find a decent converter <a href="http://www.rapidtables.com/web/color/RGB_Color.htm">here.</a></p> 
<p>The HSV Values: <br>
Gimp   --> H: 0 - 180, S: 0 - 255, V: 0 - 255 <br>
OpenCV --> H: 0 - 360, S: 0 - 100, V: 0 - 100 <br>
Please do take note!
</p>
<p>Detecting yellow works as well!</p>
<a href="http://s1367.photobucket.com/user/BrianSYC/media/tracker_zpsfed780a3.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/tracker_zpsfed780a3.jpg" border="0" alt=" photo tracker_zpsfed780a3.jpg"/></a>

<a href="http://s1367.photobucket.com/user/BrianSYC/media/threshold_zps2e83c26a.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/threshold_zps2e83c26a.jpg" border="0" alt=" photo threshold_zps2e83c26a.jpg"/></a>
<p></p>

<h3>[3.3] Hough Transform</h3>

<p>To tell you honestly, this is no blue milk run. Hough transform is a feature extraction technique that basically can help you identify any shape you want, depending on a series of calculations.</p>

<p>There are two codes relating to Hough Transform in the repository. Lines and VideoLines. The program, Lines, requires you to preload a single .jpeg or .png image before the program can run. This can be done by placing the image you want right next to the .py file and specifying the name of the image in the program itself. By default, the program will be looking for an image named "threshold.jpg". You can replace that with whatever your image is called. The second program, VideoLines, is a program that does the same Hough Transform except that it processes a video feed directly from the camera! </p>

<a href="http://s1367.photobucket.com/user/BrianSYC/media/79a635a3-6f18-4788-b0c3-ccef89b20a4e_zps7dd345d8.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/79a635a3-6f18-4788-b0c3-ccef89b20a4e_zps7dd345d8.jpg" border="0" alt=" photo 79a635a3-6f18-4788-b0c3-ccef89b20a4e_zps7dd345d8.jpg"/></a>
<p></p>

<p>As you can see here, the green lines are indications of where the Hough Transform technique indentifies there to be lines.</p>

 
<h3>[4.0] Testing the Program</h3> 
<p>It's time to test out the program! Hopefully, it can detect black underwater!</p>   
<p></p> 
<p>This was the setup i used for testing:</p>     
<p></p>
<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0473_zps13fcd8d7.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0473_zps13fcd8d7.jpg" border="0" alt=" photo IMG_0473_zps13fcd8d7.jpg"/></a>  
<p></p> 
<p>The setup basically consists of a watertight box fitted with the Raspberry Pi, 5V 1A Battery Pack and a temporary circuit for a magnetic switch.</p>
<p></p>
<p>There will be a continous stream of processed video stream. However when a magnet is brought near the magnetic switch, the contacts will close and the Raspberry Pi will capture two .jpg images from the video feed. The only thing holding me back now is the ridiculous 371 PSI haze...</p> 
<p></p>
<p>The haze reached a high of 401 PSI! And the N95 masks are all sold out! And Singaporeans are still queuing for Hello Kitties! Ok back to work.</p>
<p></p>
<p>We have changed the design of our testing kit due to one major reason. There wasn't enough space (it was intended for computer vision callibration only). We changed it to a bigger LocknLock box as shown below.</p>

<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0486_zps3e5df5e1.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0486_zps3e5df5e1.jpg" border="0" alt=" photo IMG_0486_zps3e5df5e1.jpg"/></a>
<p></p>
<p>As you can see, we have made two major modifications to the box. Firstly, we have made a hole at the side of the box and resealed it with a piece of transparent acrylic and epoxy that smells like dead fish. This is so that our computer vision will not be hindered underwater.(The box is slightly translucent) The second modification is that we have attached a breadboard at the side of the box for our circuitry. We have tested the box for it's "waterproof-ness" at the SP swimming pool, for 10 mins at 2m depth. No leakages!</p>
<p></p>
<p>We have also managed to fit all that we need inside the box as shown below.</p>

<a href="http://s1367.photobucket.com/user/BrianSYC/media/IMG_0492_zps6cdb097a.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/IMG_0492_zps6cdb097a.jpg" border="0" alt=" photo IMG_0492_zps6cdb097a.jpg"/></a>
<p></p>
<a href="http://s1367.photobucket.com/user/BrianSYC/media/TestKit_zpsbe50ea19.jpg.html" target="_blank"><img src="http://i1367.photobucket.com/albums/r794/BrianSYC/TestKit_zpsbe50ea19.jpg" border="0" alt=" photo TestKit_zpsbe50ea19.jpg"/></a>
<p></p>
<p>We have written a program known as <code>run.py</code> that basically provides a simple user interface that gives access to all the test programs. (yellowtest,blacktest,compasssensor)The program will prompt you to select the testing program you wish to execute. Then it will wait for a input from the magnetic sensor before it executes the selected program. A blue LED will be lit the moment the program executes. We have also reorganised the components within the box in such a way where you will not need to retrieve the components to recalibrate them. The placement of components is as shown above.</p>



<h3>[4.1] Pool Testing</h3>
<p></p>

<h3>[5.0] Bugs</h3>

<p>This is a list of known bugs that i have identified. I may not be able to fix them with the amount of time left here. I have also received permission from my Supervisor to stop work on computer vision to aid the rest of the systems that my team mates are handling.</p>

<p>-[Yellow.py and Black.py] Unable to startup if no colour blob detected. (Can be fixed by disabling tracker dot)<br>
-[VideoLines.py] Runs well but crashes the moment no lines are detected. O.O
</p>

 
<h3>[6.0] Colour + Patterns</h3> 

<p>I just had a discussion with Dr Carlos regarding my computer vision. I told him about the problem that has been bugging me for some time. (Specified below)</p>

<p>One of the current programs that we have can detect blobs of colour, determine the largest colour blob and place a blue tracker dot on the center of that blob. The other program can detect lines using the Hough Transform technique. I originally intended to combine these two programs so that our AUV will be able to identify shapes and colours within the playfield. The problem was how.</p>

<p>Dr Carlos highlighted an alternate solution. In RoboCup (Soccer) Robots had to identify colours and patterns . For example, the goalpost was a combination of yellow and blue. But so was the flagpole at the side of the field! However, the patterns of colours of the pole and goalpost were different! For example, the goalpost had a stripe design of yellow and blue while the flagpole was of a different pattern altogether. So they made use of these patterns to differentiate objects.</p>

<p>So i was thinking of a solution for our robot. Our colours are mainly Black and Yellow. So it should be possible differentiate patterns of Black and Yellow. For example.</p>

<p>Detecting Flare: <br>
Since the BLACK LINE and the YELLOW POLE are touching each other, the black and yellow blobs will be touching each other in the thresholded image! So if that condition is fulfilled, hit the center of the yellow blob.</p>

<p>Avoid Yellow Cage: <br>
Since the BLACK LINE and the YELLOW CAGE are separate from one another, the black and yellow blobs will be also separate from one another in the thresholded image. So if that condition is fulfilled, avoid the yellow blobs.</p>
 
 
 
<p></p>  
<p></p>
<h1 align=center>                                   Good Luck!</h1> 
<p align=center>                      and thank you very hamnida for reading</p>
 
      </section>



    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
